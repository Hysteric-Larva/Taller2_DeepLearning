{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.optimizers import SGD,RMSprop,Adamax,Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten,Conv2D, MaxPooling2D,LeakyReLU,GaussianDropout,GlobalMaxPooling2D,SpatialDropout2D\n",
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
    "from tensorflow.keras.initializers import he_uniform\n",
    "from keras.constraints import max_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Only for test porpouse.\n",
    "from gem.utils import graph_util, plot_util\n",
    "from gem.evaluation import visualize_embedding as viz\n",
    "from gem.evaluation import evaluate_graph_reconstruction as gr\n",
    "\n",
    "\n",
    "from gem.embedding.gf       import GraphFactorization\n",
    "from gem.embedding.hope     import HOPE\n",
    "from gem.embedding.lap      import LaplacianEigenmaps\n",
    "from gem.embedding.lle      import LocallyLinearEmbedding\n",
    "from gem.embedding.node2vec import node2vec\n",
    "from gem.embedding.sdne     import SDNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_extract(names_data,path):\n",
    "    data_list=[]\n",
    "    for i in names_data:\n",
    "        sentence = \"\"\n",
    "        data_path = path + str(i)+\".txt\"\n",
    "        text= open(data_path,'r')\n",
    "        for x in text:\n",
    "            sentence+=str(x)\n",
    "        data_list.append(sentence)\n",
    "        \n",
    "        text.close()\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_extractor(data):\n",
    "    full_extraction=[]\n",
    "    for i in data:\n",
    "        data_aux=\"\"\n",
    "        partial_extraction=[]\n",
    "        data_aux=i.replace(\"'\",\"\")\n",
    "        data_aux=data_aux.replace(\"[\",\"\")\n",
    "        data_aux=data_aux.replace(\"]\",\"\")\n",
    "        data_aux=data_aux.replace(\"->\",\",\")\n",
    "        data_aux=data_aux.replace(\" \",\"\")\n",
    "        data_aux=data_aux.split(\"\\n\")\n",
    "        for j in data_aux:\n",
    "            if 'ROOT' in j:\n",
    "                continue\n",
    "            else:\n",
    "                list_aux= j.split(\",\")\n",
    "                partial_extraction.append(list_aux)\n",
    "        full_extraction.append(partial_extraction)\n",
    "    return full_extraction\n",
    "def train_data_transform(data):\n",
    "    for x in range(len(data)):\n",
    "        for y in range(len(data[x])):\n",
    "            for z in range(len(data[x][y])):\n",
    "                if data[x][y][z]!='':\n",
    "                    data[x][y][z] = float(data[x][y][z])\n",
    "                else:\n",
    "                    data[x][y][z]=0\n",
    "    return data\n",
    "def X_data_import(names_data,path):\n",
    "    X = txt_extract(names_data,path)\n",
    "    X = relation_extractor(X)\n",
    "    X = train_data_transform(X)\n",
    "    X = np.array(X)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt_original_extract(name):\n",
    "    original_list=[]\n",
    "    data=open(name,'r')\n",
    "    data_read=[line.rstrip('\\n') for line in data]\n",
    "    for x in data_read:\n",
    "        aux_list=[]\n",
    "        x_aux=x.split(\"\\t\",1)\n",
    "        original_id=x_aux[0]\n",
    "        x_aux.remove(original_id)\n",
    "        x_aux = \" \".join(str(w) for w in x_aux)\n",
    "        aux_list.append(original_id)\n",
    "        aux_list.append(x_aux)\n",
    "        original_list.append(aux_list)\n",
    "    data.close()\n",
    "    return original_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cat_encode(data,cat):\n",
    "    data=list(data)\n",
    "    cat=list(cat)\n",
    "    for i in range(len(data)):\n",
    "        for j in range(len(cat)):\n",
    "            if data[i]==cat[j]:\n",
    "                data[i]=j\n",
    "                break\n",
    "            else:\n",
    "                continue\n",
    "    return keras.utils.to_categorical(data,len(cat))\n",
    "    #return np.asarray(data)\n",
    "def cat_decode(data,cat):\n",
    "    #Y=data\n",
    "    Y= [np.argmax(y, axis=None, out=None) for y in data]\n",
    "    cat=list(cat)\n",
    "    \n",
    "    for i in range(len(Y)):\n",
    "        Y[i]=cat[Y[i]]\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_predict(data_x,data_set,cat,example_show):\n",
    "    pred = model.predict(data_x)\n",
    "    y_test = cat_decode(pred,cat)\n",
    "    data_set['Expected']= y_test\n",
    "    data_set.to_csv('sample_submission_1234.csv',columns=['Id','Expected'],index=False)\n",
    "    if example_show==True:\n",
    "        return print(\"Exito!\\n\",y_test[0:20])\n",
    "    else:\n",
    "        return print(\"Exito\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>original message</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>692735698349199360</td>\n",
       "      <td>north korea 'planning some kind of rocket laun...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>525008463819464704</td>\n",
       "      <td>meet kevin vickers, the hero who shot down the...</td>\n",
       "      <td>unverified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>505611045897924608</td>\n",
       "      <td>15 year old who \"swatted\" gamer convicted of d...</td>\n",
       "      <td>false</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>693466724822323200</td>\n",
       "      <td>audio recordings reveal cpr started 11 minutes...</td>\n",
       "      <td>non-rumor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>510922415468449792</td>\n",
       "      <td>awful mt @scclemons:uk aid worker david haines...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   id                                   original message  \\\n",
       "0  692735698349199360  north korea 'planning some kind of rocket laun...   \n",
       "1  525008463819464704  meet kevin vickers, the hero who shot down the...   \n",
       "2  505611045897924608  15 year old who \"swatted\" gamer convicted of d...   \n",
       "3  693466724822323200  audio recordings reveal cpr started 11 minutes...   \n",
       "4  510922415468449792  awful mt @scclemons:uk aid worker david haines...   \n",
       "\n",
       "        label  \n",
       "0   non-rumor  \n",
       "1  unverified  \n",
       "2       false  \n",
       "3   non-rumor  \n",
       "4        true  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels = pd.read_csv('./data/train_labels.csv')\n",
    "test_labels = pd.read_csv('./data/sample_submission.csv')\n",
    "train_message_path= \"./data/train_source_tweets.txt\"\n",
    "train_path = './data/train/'\n",
    "test_path = './data/test/'\n",
    "\n",
    "###########        This creates original df with original message and label      ##################33\n",
    "x_original = txt_original_extract(train_message_path)\n",
    "df_original = pd.DataFrame(x_original,  columns =['id','original message'])\n",
    "df_original['id']= df_original['id'].astype('int64')\n",
    "df_train = pd.merge(df_original, train_labels, how='inner', left_on='id', right_on='id')\n",
    "Y_train = df_train[\"label\"]\n",
    "df_train.head(5)\n",
    "\n",
    "##############################################################################33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_message = df_train[\"original message\"].values\n",
    "train_relations = X_data_import(df_train[\"id\"],train_path )\n",
    "y_train = df_train[\"label\"]\n",
    "cat = Y_train.unique()\n",
    "Y_train=cat_encode(Y_train,cat)\n",
    "input_dim=train_relations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample of train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[5402612.0,\n",
       " 6.927356983491994e+17,\n",
       " 0.0,\n",
       " 14614290.0,\n",
       " 6.927356983491994e+17,\n",
       " 0.63]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_relations[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
